{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport warnings\\n\\n# 특정 경고를 무시하고 싶을 때\\nwarnings.filterwarnings('ignore', category=)\\n\\n# 모든 경고를 무시하고 싶을 때 (주의: 일반적으로 권장되지 않음)\\nwarnings.filterwarnings('ignore')\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import warnings\n",
    "\n",
    "# 특정 경고를 무시하고 싶을 때\n",
    "warnings.filterwarnings('ignore', category=)\n",
    "\n",
    "# 모든 경고를 무시하고 싶을 때 (주의: 일반적으로 권장되지 않음)\n",
    "warnings.filterwarnings('ignore')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from learntools.core import binder\n",
    "#binder.bind(globals())\n",
    "#from learntools.machine_learning.ex7 import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set up filepaths\n",
    "if not os.path.exists(\"/Users/hj/Desktop/ESTCODE/home-data-for-ml-course/train.csv\"):\n",
    "    os.symlink(\"/Users/hj/Desktop/ESTCODE/home-data-for-ml-course/train.csv\")  \n",
    "    os.symlink(\"/Users/hj/Desktop/ESTCODE/home-data-for-ml-course/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "\n",
    "def get_X(df:pd.DataFrame, features:iter=['LotArea', 'MSSubClass', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd','MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
    "    '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath',\n",
    "    'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "    'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
    "    'PoolArea', 'MiscVal', 'MoSold', 'YrSold'], scaler= 'minmax', scale_columns = None):\n",
    "    standard = StandardScaler()\n",
    "    maxabs = MaxAbsScaler()\n",
    "    minmax = MinMaxScaler()\n",
    "\n",
    "    # df1 = pd.get_dummies(df[features]).to_numpy(dtype=np.float32)\n",
    "    df1 = pd.get_dummies(df[features])\n",
    "    if scale_columns :\n",
    "        if scaler == 'standard':\n",
    "          df1[scale_columns] = standard.fit_transform(df1[scale_columns])\n",
    "        elif scaler == 'maxabs':\n",
    "          df1[scale_columns] = maxabs.fit_transform(df1[scale_columns])\n",
    "        elif scaler == 'minmax':\n",
    "            df1[scale_columns] = minmax.fit_transform(df1[scale_columns])\n",
    "\n",
    "    return df1.to_numpy(dtype=np.float32)\n",
    "\n",
    "def get_y(df:pd.DataFrame, feature_name = \"Survived\"):\n",
    "  '''Make the target from a DataFrame.\n",
    "\n",
    "  Args:\n",
    "      df: DataFrame\n",
    "  '''\n",
    "  return df[feature_name].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n",
      "MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold\n",
      "False       False    False        False        False      False         False     False     False         False      False     False     False         False         False         False       False       False        False          False      False        False     False    False   False     1460\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7829"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from preprocess import get_X, get_y\n",
    "\n",
    "# Load the data, and separate the target\n",
    "iowa_file_path = '/Users/hj/Desktop/ESTCODE/home-data-for-ml-course/train.csv'\n",
    "train_df = pd.read_csv(iowa_file_path)\n",
    "#y = train_df.SalePrice\n",
    "\n",
    "# Create X (After completing the exercise, you can return to modify this line!)\n",
    "features = ['LotArea', 'MSSubClass', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "features = ['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
    "    '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath',\n",
    "    'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "    'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
    "    'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
    "print(train_df.columns)\n",
    "\n",
    "# Select columns corresponding to features, and preview the data\n",
    "X = get_X(train_df,features)\n",
    "y = train_df.SalePrice.to_numpy(dtype=np.float32)\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=42)\n",
    "'''\n",
    "# Define a random forest model\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "'''\n",
    "\n",
    "#print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n",
    "\n",
    "train_df.head()\n",
    "train_df['Fence'].value_counts()\n",
    "print(train_df[features].isnull().value_counts())\n",
    "train_df.isnull().sum()\n",
    "train_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1095, 25), (1095,), (365, 25), (365,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape, val_X.shape, val_y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Neuarl Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hj/anaconda3/envs/MathAI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nn import ANN #nn모듈에서 ANN임포트\n",
    "from utils import CustomDataset\n",
    "from train import train_one_epoch, evaluate\n",
    "from torchmetrics.classification import BinaryConfusionMatrix, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hj/anaconda3/envs/MathAI/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/300 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/hj/work/hello/houseprice/houseprice.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hj/work/hello/houseprice/houseprice.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hj/work/hello/houseprice/houseprice.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m   mse \u001b[39m=\u001b[39m MeanSquaredError()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hj/work/hello/houseprice/houseprice.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m   loss \u001b[39m=\u001b[39m train_one_epoch(net, nn\u001b[39m.\u001b[39;49mMSELoss, optimizer, dl, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hj/work/hello/houseprice/houseprice.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m   loss_val \u001b[39m=\u001b[39m evaluate(net, nn\u001b[39m.\u001b[39mMSELoss, dl_val, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hj/work/hello/houseprice/houseprice.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m   acc_val \u001b[39m=\u001b[39m mse\u001b[39m.\u001b[39mcompute()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/work/hello/houseprice/train.py:28\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, optimizer, data_loader, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m output \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m---> 28\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y)\n\u001b[1;32m     29\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/modules/loss.py:532\u001b[0m, in \u001b[0;36mMSELoss.__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, size_average\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, reduce\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, reduction: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(size_average, reduce, reduction)\n",
      "File \u001b[0;32m~/anaconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/modules/loss.py:23\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39;49mlegacy_get_string(size_average, reduce)\n\u001b[1;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction \u001b[39m=\u001b[39m reduction\n",
      "File \u001b[0;32m~/anaconda3/envs/MathAI/lib/python3.10/site-packages/torch/nn/_reduction.py:35\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     reduce \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mand\u001b[39;00m reduce:\n\u001b[1;32m     36\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[39melif\u001b[39;00m reduce:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchmetrics.regression import MeanAbsoluteError, MeanSquaredError\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2023)\n",
    "\n",
    "nets = [ANN(input_dim=25).to(device) for i in range(n_splits)]\n",
    "history = []\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(train_X, train_y)):\n",
    "  X, y = torch.tensor(train_X[trn_idx]), torch.tensor(train_y[trn_idx]).unsqueeze(-1)\n",
    "  \n",
    "  #X = torch.tensor(train_X[trn_idx]), torch.tensor(train_y[trn_idx])\n",
    "  #y = torch.tensor(train_X[trn_idx]), torch.tensor(train_y[trn_idx]).unsqueeze(-1)\n",
    "  \n",
    "\n",
    "\n",
    "  X_val, y_val = torch.tensor(train_X[val_idx]), torch.tensor(train_y[val_idx]).unsqueeze(-1)\n",
    "\n",
    "  # ds = TensorDataset(X, y)\n",
    "  # ds_val = TensorDataset(X_val, y_val)\n",
    "  ds = CustomDataset(X, y)\n",
    "  ds_val = CustomDataset(X_val, y_val)\n",
    "  dl = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "  dl_val = DataLoader(ds_val, batch_size=len(ds_val), shuffle=False)\n",
    "\n",
    "  net = nets[i]\n",
    "  optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "  pbar = tqdm(range(300))\n",
    "  for j in pbar:\n",
    "    mse = MeanSquaredError()\n",
    "    loss = train_one_epoch(net, nn.MSELoss(), optimizer, dl, device)\n",
    "    loss_val = evaluate(net, nn.MSELoss(), dl_val, device)\n",
    "    acc_val = mse.compute().item()\n",
    "    pbar.set_postfix(trn_loss=loss, val_loss=loss_val, val_acc=acc_val)\n",
    "\n",
    "  #bcm = BinaryConfusionMatrix().to(device)\n",
    "  #evaluate(net, nn.functional.mse_loss, dl_val, device, bcm)\n",
    "  #history.append(bcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([876, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MathAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
