{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic tutorial\n",
    "- EDA\n",
    "- sklearn\n",
    "- ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 을 그릴 때, FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version 제거\n",
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# heatmap 같은 경우, 데이터가 커지면 수치가 잘 안 보인다\n",
    "# plot 사이즈를 키운다\n",
    "# sns.set(rc={'figure.figsize':(10,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('titanic/train.csv')\n",
    "df_test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of women who survived: 0.7420382165605095\n"
     ]
    }
   ],
   "source": [
    "women = df_train.loc[df_train.Sex == 'female'][\"Survived\"]\n",
    "rate_women = sum(women)/len(women)\n",
    "\n",
    "print(\"% of women who survived:\", rate_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of men who survived: 0.18890814558058924\n"
     ]
    }
   ],
   "source": [
    "men = df_train.loc[df_train.Sex == 'male'][\"Survived\"]\n",
    "rate_men = sum(men)/len(men)\n",
    "\n",
    "print(\"% of men who survived:\", rate_men)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Results\n",
    "- 0.77511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = df_train[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(df_train[features])\n",
    "X_test = pd.get_dummies(df_test[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Start\n",
    "- 데이터들을 카테고리화 한다\n",
    "- one hot encoding 을 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  family  \n",
       "0        0         A/5 21171   7.2500   NaN        S  Single  \n",
       "1        0          PC 17599  71.2833   C85        C  Single  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  Single  \n",
       "3        0            113803  53.1000  C123        S  Single  \n",
       "4        0            373450   8.0500   NaN        S  Single  \n",
       "..     ...               ...      ...   ...      ...     ...  \n",
       "886      0            211536  13.0000   NaN        S  Single  \n",
       "887      0            112053  30.0000   B42        S  Single  \n",
       "888      2        W./C. 6607  23.4500   NaN        S   Small  \n",
       "889      0            111369  30.0000  C148        C  Single  \n",
       "890      0            370376   7.7500   NaN        Q  Single  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 별 가족수를 카테고리화 한다.\n",
    "\n",
    "df_train[\"family\"] = df_train.SibSp + df_train.Parch\n",
    "df_test[\"family\"] = df_test.SibSp + df_test.Parch\n",
    "\n",
    "def change_family_category(x):\n",
    "  if x < 2: return \"Single\"\n",
    "  if x == 2: return \"Couple\"\n",
    "  if x < 5: return \"Small\"\n",
    "  if x >= 5: return \"Large\"\n",
    "\n",
    "df_train.family = df_train.family.apply(change_family_category)\n",
    "df_test.family = df_test.family.apply(change_family_category)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>is_baby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>0.129801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.460580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_baby</th>\n",
       "      <td>0.129801</td>\n",
       "      <td>-0.460580</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived       Age   is_baby\n",
       "Survived  1.000000 -0.077221  0.129801\n",
       "Age      -0.077221  1.000000 -0.460580\n",
       "is_baby   0.129801 -0.460580  1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5세 미만의 아동들의 생존률\n",
    "df_train_baby_survive = df_train.loc[:, ['Survived', 'Age']]\n",
    "df_train_baby_survive.fillna(df_train.Age.median())\n",
    "df_train_baby_survive['is_baby'] = df_train_baby_survive.Age.map(lambda age: 1 if age < 5 else 0)\n",
    "\n",
    "df_train_baby_survive_test = df_test.loc[:, ['Age']]\n",
    "df_train_baby_survive_test.fillna(df_train.Age.median())\n",
    "df_train_baby_survive_test['is_baby'] = df_train_baby_survive_test.Age.map(lambda age: 1 if age < 5 else 0)\n",
    "\n",
    "df_train_baby_survive.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is_baby one hot encoding\n",
    "df_train[\"is_baby\"] = df_train_baby_survive.is_baby.copy()\n",
    "df_test[\"is_baby\"] = df_train_baby_survive_test.is_baby.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get initial from names\n",
    "\n",
    "def get_initial(name:str):\n",
    "  return name.split(',')[1].split('.')[0].strip()\n",
    "df_train.Name.apply(get_initial).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Master</th>\n",
       "      <th>Don</th>\n",
       "      <th>Rev</th>\n",
       "      <th>Dr</th>\n",
       "      <th>Mme</th>\n",
       "      <th>Ms</th>\n",
       "      <th>Major</th>\n",
       "      <th>Lady</th>\n",
       "      <th>Sir</th>\n",
       "      <th>Mlle</th>\n",
       "      <th>Col</th>\n",
       "      <th>Capt</th>\n",
       "      <th>the Countess</th>\n",
       "      <th>Jonkheer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.549199</td>\n",
       "      <td>0.339040</td>\n",
       "      <td>0.327093</td>\n",
       "      <td>0.085221</td>\n",
       "      <td>-0.026456</td>\n",
       "      <td>-0.064988</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.042470</td>\n",
       "      <td>0.042470</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.042470</td>\n",
       "      <td>0.042470</td>\n",
       "      <td>0.060095</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>-0.026456</td>\n",
       "      <td>0.042470</td>\n",
       "      <td>-0.026456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>-0.549199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.096808</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.039411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>0.339040</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.033262</td>\n",
       "      <td>-0.035947</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.019160</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.019160</td>\n",
       "      <td>-0.019160</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.013541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>0.327093</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.041717</td>\n",
       "      <td>-0.045085</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.024031</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.024031</td>\n",
       "      <td>-0.024031</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.016983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0.085221</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.017851</td>\n",
       "      <td>-0.019292</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.007267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>-0.026456</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>-0.064988</td>\n",
       "      <td>-0.096808</td>\n",
       "      <td>-0.033262</td>\n",
       "      <td>-0.041717</td>\n",
       "      <td>-0.017851</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007327</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>0.008185</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.035947</td>\n",
       "      <td>-0.045085</td>\n",
       "      <td>-0.019292</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.007327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>0.042470</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0.042470</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0.011329</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.019160</td>\n",
       "      <td>-0.024031</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.002250</td>\n",
       "      <td>-0.002250</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>0.042470</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0.042470</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>0.060095</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.019160</td>\n",
       "      <td>-0.024031</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.002250</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002250</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0.011329</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.019160</td>\n",
       "      <td>-0.024031</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.002250</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.002250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>-0.026456</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Countess</th>\n",
       "      <td>0.042470</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>-0.026456</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Survived        Mr       Mrs      Miss    Master       Don  \\\n",
       "Survived      1.000000 -0.549199  0.339040  0.327093  0.085221 -0.026456   \n",
       "Mr           -0.549199  1.000000 -0.474952 -0.595692 -0.254903 -0.039411   \n",
       "Mrs           0.339040 -0.474952  1.000000 -0.204670 -0.087580 -0.013541   \n",
       "Miss          0.327093 -0.595692 -0.204670  1.000000 -0.109844 -0.016983   \n",
       "Master        0.085221 -0.254903 -0.087580 -0.109844  1.000000 -0.007267   \n",
       "Don          -0.026456 -0.039411 -0.013541 -0.016983 -0.007267  1.000000   \n",
       "Rev          -0.064988 -0.096808 -0.033262 -0.041717 -0.017851 -0.002760   \n",
       "Dr            0.008185 -0.104624 -0.035947 -0.045085 -0.019292 -0.002983   \n",
       "Mme           0.042470 -0.039411 -0.013541 -0.016983 -0.007267 -0.001124   \n",
       "Ms            0.042470 -0.039411 -0.013541 -0.016983 -0.007267 -0.001124   \n",
       "Major         0.011329 -0.055767 -0.019160 -0.024031 -0.010283 -0.001590   \n",
       "Lady          0.042470 -0.039411 -0.013541 -0.016983 -0.007267 -0.001124   \n",
       "Sir           0.042470 -0.039411 -0.013541 -0.016983 -0.007267 -0.001124   \n",
       "Mlle          0.060095 -0.055767 -0.019160 -0.024031 -0.010283 -0.001590   \n",
       "Col           0.011329 -0.055767 -0.019160 -0.024031 -0.010283 -0.001590   \n",
       "Capt         -0.026456 -0.039411 -0.013541 -0.016983 -0.007267 -0.001124   \n",
       "the Countess  0.042470 -0.039411 -0.013541 -0.016983 -0.007267 -0.001124   \n",
       "Jonkheer     -0.026456 -0.039411 -0.013541 -0.016983 -0.007267 -0.001124   \n",
       "\n",
       "                   Rev        Dr       Mme        Ms     Major      Lady  \\\n",
       "Survived     -0.064988  0.008185  0.042470  0.042470  0.011329  0.042470   \n",
       "Mr           -0.096808 -0.104624 -0.039411 -0.039411 -0.055767 -0.039411   \n",
       "Mrs          -0.033262 -0.035947 -0.013541 -0.013541 -0.019160 -0.013541   \n",
       "Miss         -0.041717 -0.045085 -0.016983 -0.016983 -0.024031 -0.016983   \n",
       "Master       -0.017851 -0.019292 -0.007267 -0.007267 -0.010283 -0.007267   \n",
       "Don          -0.002760 -0.002983 -0.001124 -0.001124 -0.001590 -0.001124   \n",
       "Rev           1.000000 -0.007327 -0.002760 -0.002760 -0.003905 -0.002760   \n",
       "Dr           -0.007327  1.000000 -0.002983 -0.002983 -0.004221 -0.002983   \n",
       "Mme          -0.002760 -0.002983  1.000000 -0.001124 -0.001590 -0.001124   \n",
       "Ms           -0.002760 -0.002983 -0.001124  1.000000 -0.001590 -0.001124   \n",
       "Major        -0.003905 -0.004221 -0.001590 -0.001590  1.000000 -0.001590   \n",
       "Lady         -0.002760 -0.002983 -0.001124 -0.001124 -0.001590  1.000000   \n",
       "Sir          -0.002760 -0.002983 -0.001124 -0.001124 -0.001590 -0.001124   \n",
       "Mlle         -0.003905 -0.004221 -0.001590 -0.001590 -0.002250 -0.001590   \n",
       "Col          -0.003905 -0.004221 -0.001590 -0.001590 -0.002250 -0.001590   \n",
       "Capt         -0.002760 -0.002983 -0.001124 -0.001124 -0.001590 -0.001124   \n",
       "the Countess -0.002760 -0.002983 -0.001124 -0.001124 -0.001590 -0.001124   \n",
       "Jonkheer     -0.002760 -0.002983 -0.001124 -0.001124 -0.001590 -0.001124   \n",
       "\n",
       "                   Sir      Mlle       Col      Capt  the Countess  Jonkheer  \n",
       "Survived      0.042470  0.060095  0.011329 -0.026456      0.042470 -0.026456  \n",
       "Mr           -0.039411 -0.055767 -0.055767 -0.039411     -0.039411 -0.039411  \n",
       "Mrs          -0.013541 -0.019160 -0.019160 -0.013541     -0.013541 -0.013541  \n",
       "Miss         -0.016983 -0.024031 -0.024031 -0.016983     -0.016983 -0.016983  \n",
       "Master       -0.007267 -0.010283 -0.010283 -0.007267     -0.007267 -0.007267  \n",
       "Don          -0.001124 -0.001590 -0.001590 -0.001124     -0.001124 -0.001124  \n",
       "Rev          -0.002760 -0.003905 -0.003905 -0.002760     -0.002760 -0.002760  \n",
       "Dr           -0.002983 -0.004221 -0.004221 -0.002983     -0.002983 -0.002983  \n",
       "Mme          -0.001124 -0.001590 -0.001590 -0.001124     -0.001124 -0.001124  \n",
       "Ms           -0.001124 -0.001590 -0.001590 -0.001124     -0.001124 -0.001124  \n",
       "Major        -0.001590 -0.002250 -0.002250 -0.001590     -0.001590 -0.001590  \n",
       "Lady         -0.001124 -0.001590 -0.001590 -0.001124     -0.001124 -0.001124  \n",
       "Sir           1.000000 -0.001590 -0.001590 -0.001124     -0.001124 -0.001124  \n",
       "Mlle         -0.001590  1.000000 -0.002250 -0.001590     -0.001590 -0.001590  \n",
       "Col          -0.001590 -0.002250  1.000000 -0.001590     -0.001590 -0.001590  \n",
       "Capt         -0.001124 -0.001590 -0.001590  1.000000     -0.001124 -0.001124  \n",
       "the Countess -0.001124 -0.001590 -0.001590 -0.001124      1.000000 -0.001124  \n",
       "Jonkheer     -0.001124 -0.001590 -0.001590 -0.001124     -0.001124  1.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_initial_survive = df_train.loc[:, ['Survived', 'Name']]\n",
    "df_train_initial_survive['initial'] = df_train_initial_survive.Name.apply(get_initial)\n",
    "\n",
    "for initial in df_train_initial_survive['initial'].unique():\n",
    "  df_train_initial_survive[initial] = df_train_initial_survive['initial'].map(lambda x: 1 if x == initial else 0)\n",
    "\n",
    "df_train_initial_survive.drop(columns=[\"initial\", \"Name\"], inplace=True)  \n",
    "df_train_initial_survive.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_initial_survive = df_train.loc[:, ['Survived', 'Name']]\n",
    "df_train_initial_survive['initial'] = df_train_initial_survive.Name.apply(get_initial)\n",
    "\n",
    "special_initials = ['Mr', 'Mrs', 'Miss']\n",
    "df_train_initial_survive['initial'] = df_train_initial_survive['initial'].map(lambda x: x if x in special_initials else \"Others\")\n",
    "df_train['initial'] = df_train_initial_survive['initial'].copy()\n",
    "\n",
    "\n",
    "# get dummies 에서 해주고 있기 때문에 지웁니다.\n",
    "# label incoder랑 같은 역할을 해준다.\n",
    "\n",
    "# special_initials = ['Mr', 'Mrs', 'Miss']\n",
    "# for initial in special_initials:\n",
    "#   df_train_initial_survive[initial] = df_train_initial_survive['initial'].map(lambda x: 1 if x == initial else 0)\n",
    "\n",
    "\n",
    "# df_train_initial_survive['Others'] = df_train_initial_survive.initial.map(lambda x: 0 if x in special_initials else 1)\n",
    "# df_train_initial_survive.drop(columns=[\"initial\", \"Name\"], inplace=True)\n",
    "# df_train_initial_survive.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_dummies 에서 해주기 때문에 지웁니다.\n",
    "\n",
    "# df_train['Mr'] = df_train_initial_survive.Mr.copy()\n",
    "# df_train['Mrs'] = df_train_initial_survive.Mrs.copy()\n",
    "# df_train['Miss'] = df_train_initial_survive.Miss.copy()\n",
    "# df_train['Others'] = df_train_initial_survive.Others.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_initial_survive = df_test.loc[:, ['Name']]\n",
    "df_test_initial_survive['initial'] = df_test_initial_survive.Name.apply(get_initial)\n",
    "\n",
    "special_initials = ['Mr', 'Mrs', 'Miss']\n",
    "df_test_initial_survive['initial'] = df_test_initial_survive['initial'].map(lambda x: x if x in special_initials else \"Others\")\n",
    "df_test['initial'] = df_test_initial_survive['initial'].copy()\n",
    "\n",
    "# 밑에서 pd.dummies 가 다 해주기 때문에 지웁니다.\n",
    "\n",
    "# special_initials = ['Mr', 'Mrs', 'Miss']\n",
    "# for initial in special_initials:\n",
    "#   df_test_initial_survive[initial] = df_test_initial_survive['initial'].map(lambda x: 1 if x == initial else 0)\n",
    "\n",
    "\n",
    "# df_test_initial_survive['Others'] = df_test_initial_survive.initial.map(lambda x: 0 if x in special_initials else 1)\n",
    "# df_test_initial_survive.drop(columns=[\"initial\", \"Name\"], inplace=True)\n",
    "\n",
    "# df_test['Mr'] = df_test_initial_survive.Mr.copy()\n",
    "# df_test['Mrs'] = df_test_initial_survive.Mrs.copy()\n",
    "# df_test['Miss'] = df_test_initial_survive.Miss.copy()\n",
    "# df_test['Others'] = df_test_initial_survive.Others.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Pclass = df_train.Pclass.map(lambda x : f\"Pclass_{x}\")\n",
    "df_test.Pclass = df_test.Pclass.map(lambda x : f\"Pclass_{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mode is the value that appears most often\n",
    "df_train.Embarked.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 추가\n",
    "df_train.Embarked.fillna(df_train.Embarked.mode()[0], inplace=True)\n",
    "df_test.Embarked.fillna(df_test.Embarked.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 추가\n",
    "df_train.Fare.fillna(df_train.Fare.median(), inplace=True)\n",
    "df_test.Fare.fillna(df_test.Fare.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RainForest Tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'family', 'is_baby', 'initial'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_passenger_id = df_test.PassengerId.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = df_train[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"family\", \"is_baby\", \"initial\", \"Embarked\"]\n",
    "X = pd.get_dummies(df_train[features])\n",
    "X_test = pd.get_dummies(df_test[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission2.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 submission 결과: 0.77751\n",
    "\n",
    "- Embarked 를 추가하고 나서 오히려 미세하게 증가함.\n",
    "- 데이터 컬럼의 양에 따라서 정확도가 올라갈 수 있구나 알 수 있음\n",
    "- 데이터 분석이 미흡했구나 알 수 있었다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['family', 'is_baby', 'initial'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m features \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mPclass\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSex\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfamily\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mis_baby\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minitial\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mEmbarked\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     12\u001b[0m df_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mtitanic/train.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(df_train[features])\u001b[39m.\u001b[39miloc[:\u001b[39m200\u001b[39m]\n\u001b[1;32m     15\u001b[0m y \u001b[39m=\u001b[39m df_train[\u001b[39m\"\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[:\u001b[39m200\u001b[39m]  \u001b[39m# Ensure y has the same number of samples as X\u001b[39;00m\n\u001b[1;32m     17\u001b[0m rf_model \u001b[39m=\u001b[39m RandomForestClassifier()\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/pandas/core/indexes/base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/pandas/core/indexes/base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['family', 'is_baby', 'initial'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "#features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"family\", \"is_baby\", \"initial\", \"Embarked\"]\n",
    "\n",
    "df_train = pd.read_csv('titanic/train.csv')\n",
    "\n",
    "X = pd.get_dummies(df_train[features]).iloc[:200]\n",
    "y = df_train[\"Survived\"].iloc[:200]  # Ensure y has the same number of samples as X\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "kf = KFold(n_splits=30)\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    predictions = rf_model.predict(X_test)\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_test, predictions))\n",
    "    precisions.append(precision_score(y_test, predictions))\n",
    "    recalls.append(recall_score(y_test, predictions))\n",
    "    f1_scores.append(f1_score(y_test, predictions))\n",
    "\n",
    "    print(f\"Confusion Matrix (Fold {len(accuracies)}):\\n{confusion_matrix(y_test, predictions)}\\n\")\n",
    "\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 Score: {average_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Fold 1):\n",
      "[[5 0]\n",
      " [0 5]]\n",
      "\n",
      "Confusion Matrix (Fold 2):\n",
      "[[4 1]\n",
      " [1 4]]\n",
      "\n",
      "Confusion Matrix (Fold 3):\n",
      "[[4 1]\n",
      " [3 2]]\n",
      "\n",
      "Confusion Matrix (Fold 4):\n",
      "[[6 0]\n",
      " [2 2]]\n",
      "\n",
      "Confusion Matrix (Fold 5):\n",
      "[[4 3]\n",
      " [0 3]]\n",
      "\n",
      "Confusion Matrix (Fold 6):\n",
      "[[5 0]\n",
      " [1 4]]\n",
      "\n",
      "Confusion Matrix (Fold 7):\n",
      "[[6 0]\n",
      " [2 2]]\n",
      "\n",
      "Confusion Matrix (Fold 8):\n",
      "[[7 0]\n",
      " [2 1]]\n",
      "\n",
      "Confusion Matrix (Fold 9):\n",
      "[[5 0]\n",
      " [3 2]]\n",
      "\n",
      "Confusion Matrix (Fold 10):\n",
      "[[8 0]\n",
      " [1 1]]\n",
      "\n",
      "Confusion Matrix (Fold 11):\n",
      "[[6 1]\n",
      " [2 1]]\n",
      "\n",
      "Confusion Matrix (Fold 12):\n",
      "[[6 4]\n",
      " [0 0]]\n",
      "\n",
      "Confusion Matrix (Fold 13):\n",
      "[[6 0]\n",
      " [2 2]]\n",
      "\n",
      "Confusion Matrix (Fold 14):\n",
      "[[8 0]\n",
      " [0 2]]\n",
      "\n",
      "Confusion Matrix (Fold 15):\n",
      "[[3 4]\n",
      " [2 1]]\n",
      "\n",
      "Confusion Matrix (Fold 16):\n",
      "[[7 1]\n",
      " [0 2]]\n",
      "\n",
      "Confusion Matrix (Fold 17):\n",
      "[[6 1]\n",
      " [1 2]]\n",
      "\n",
      "Confusion Matrix (Fold 18):\n",
      "[[8 1]\n",
      " [0 1]]\n",
      "\n",
      "Confusion Matrix (Fold 19):\n",
      "[[6 0]\n",
      " [3 1]]\n",
      "\n",
      "Confusion Matrix (Fold 20):\n",
      "[[3 1]\n",
      " [2 4]]\n",
      "\n",
      "Average Accuracy: 0.775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 가정: X는 특성 데이터, y는 타겟 데이터\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "df_train = pd.read_csv('titanic/train.csv')\n",
    "df_test = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "X = pd.get_dummies(df_train[features]).iloc[:]\n",
    "y = df_train[\"Survived\"]\n",
    "\n",
    "# 랜덤 포레스트 모델 초기화\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# K-Fold 교차 검증 설정\n",
    "# 배치 사이즈를 나누듯 한 세트를 테스트 세트로 하고 나머지 네개에 대해 학습을 진행.\n",
    "# n_splits=5 전체 데이터를 5개의 세트로 나눔. - 1세트를 테스트 세트로 생각, 나머지 4개로는 학습\n",
    "# 한개의 테스트 세트를 5번 진행\n",
    "# 5번의 값의 평균을 일반화하여 정확도를 계산한다.\n",
    "kf = KFold(n_splits=20)  # 5겹 교차 검증-모델이 잘 만들었는 지 검증\n",
    "\n",
    "# 각 분할에 대한 정확도를 저장할 리스트\n",
    "# 아래 for문에 대한 5번의 값이 모두 들어있음\n",
    "accuracies = []\n",
    "conf_matrices = []  # Confusion matrices 리스트\n",
    "\n",
    "# K-Fold 교차 검증 수행\n",
    "# for문 총 5번 돔\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # 훈련 데이터와 테스트 데이터 분할\n",
    "    # print(train_index, test_index)\n",
    "    # X_train으로 학습, X_test로 테스트 진행\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    # y_train은 정답 데이터 1 or 0 (학습 데이터에 대한 정답 데이터가)\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # 모델 훈련\n",
    "    #rf_model이 학습된 모델이 들어가 있음\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # 예측 및 정확도 계산\n",
    "    # 모델이 위 학습데이터에 대한 예측값을 출력\n",
    "    predictions = rf_model.predict(X_test)\n",
    "    # 정답값과 모델이 예측한 값에 대한 비교\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    # accuracy에 대한 for문 5번이 출력됨\n",
    "    accuracies.append(accuracy)\n",
    "     # 각 Fold에 대한 혼동 행렬(Confusion Matrix)을 계산하고 이를 리스트에 추가함\n",
    "    # y_test(정답데이터)와 predictions(예측값)를 기반으로 혼동 행렬을 계산하여 그 사잇값을 행렬로 나타냄\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    # 계산된 혼동 행렬(cm)을 conf_matrices 리스트에 추가. 이는 각 Fold에 대한 혼동 행렬들을 저장.\n",
    "    conf_matrices.append(cm)\n",
    "    # 현재 Fold에 대한 혼동 행렬을 출력함. Fold 번호와 함께 혼동 행렬의 내용이 출력됨.\n",
    "    print(f\"Confusion Matrix (Fold {len(conf_matrices)}):\\n{cm}\\n\")\n",
    "\n",
    "# 평균 정확도 출력\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Fold 1):\n",
      "[[18  6]\n",
      " [ 6 15]]\n",
      "\n",
      "Confusion Matrix (Fold 2):\n",
      "[[26  1]\n",
      " [ 7 11]]\n",
      "\n",
      "Confusion Matrix (Fold 3):\n",
      "[[30  5]\n",
      " [ 5  5]]\n",
      "\n",
      "Confusion Matrix (Fold 4):\n",
      "[[29  6]\n",
      " [ 3  7]]\n",
      "\n",
      "Confusion Matrix (Fold 5):\n",
      "[[22  3]\n",
      " [10 10]]\n",
      "\n",
      "Confusion Matrix (Fold 6):\n",
      "[[22  7]\n",
      " [ 5 11]]\n",
      "\n",
      "Confusion Matrix (Fold 7):\n",
      "[[18  5]\n",
      " [ 7 15]]\n",
      "\n",
      "Confusion Matrix (Fold 8):\n",
      "[[21  1]\n",
      " [ 5 18]]\n",
      "\n",
      "Confusion Matrix (Fold 9):\n",
      "[[22  5]\n",
      " [ 3 15]]\n",
      "\n",
      "Confusion Matrix (Fold 10):\n",
      "[[20  4]\n",
      " [10 11]]\n",
      "\n",
      "Confusion Matrix (Fold 11):\n",
      "[[31  1]\n",
      " [ 6  7]]\n",
      "\n",
      "Confusion Matrix (Fold 12):\n",
      "[[21  6]\n",
      " [ 4 13]]\n",
      "\n",
      "Confusion Matrix (Fold 13):\n",
      "[[19  3]\n",
      " [ 9 13]]\n",
      "\n",
      "Confusion Matrix (Fold 14):\n",
      "[[26  3]\n",
      " [ 6  9]]\n",
      "\n",
      "Confusion Matrix (Fold 15):\n",
      "[[24  4]\n",
      " [ 7  9]]\n",
      "\n",
      "Confusion Matrix (Fold 16):\n",
      "[[23  4]\n",
      " [ 9  8]]\n",
      "\n",
      "Confusion Matrix (Fold 17):\n",
      "[[27  1]\n",
      " [ 6 10]]\n",
      "\n",
      "Confusion Matrix (Fold 18):\n",
      "[[26  3]\n",
      " [ 3 12]]\n",
      "\n",
      "Confusion Matrix (Fold 19):\n",
      "[[26  3]\n",
      " [ 8  7]]\n",
      "\n",
      "Confusion Matrix (Fold 20):\n",
      "[[24  3]\n",
      " [ 5 12]]\n",
      "\n",
      "Average Accuracy: 0.7778030303030303\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "# 가정: X는 특성 데이터, y는 타겟 데이터\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "\n",
    "X = pd.get_dummies(df_train[features]).iloc[:]\n",
    "y = df_train[\"Survived\"]\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "kf = KFold(n_splits=20)\n",
    "\n",
    "accuracies = []\n",
    "conf_matrices = []  # Confusion matrices 리스트: 분류 모델의 성능을 평가\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    predictions = rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate confusion matrix for each fold\n",
    "    # 각 Fold에 대한 혼동 행렬(Confusion Matrix)을 계산하고 이를 리스트에 추가함\n",
    "    # y_test(정답데이터)와 predictions(예측값)를 기반으로 혼동 행렬을 계산하여 그 사잇값을 행렬로 나타냄\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    # 계산된 혼동 행렬(cm)을 conf_matrices 리스트에 추가. 이는 각 Fold에 대한 혼동 행렬들을 저장.\n",
    "    conf_matrices.append(cm)\n",
    "    # 현재 Fold에 대한 혼동 행렬을 출력함. Fold 번호와 함께 혼동 행렬의 내용이 출력됨.\n",
    "    print(f\"Confusion Matrix (Fold {len(conf_matrices)}):\\n{cm}\\n\")\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Tries\n",
    "- use the same data as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  SibSp  Parch  Sex_female  Sex_male\n",
       "0         3      1      0       False      True\n",
       "1         1      1      0        True     False\n",
       "2         3      0      0        True     False\n",
       "3         1      1      0        True     False\n",
       "4         3      0      0       False      True\n",
       "..      ...    ...    ...         ...       ...\n",
       "886       2      0      0       False      True\n",
       "887       1      0      0        True     False\n",
       "888       3      1      2        True     False\n",
       "889       1      0      0       False      True\n",
       "890       3      0      0       False      True\n",
       "\n",
       "[891 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = data.DataLoader(pd.get_dummies(df_train[features]), shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[1;32m      4\u001b[0m loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 5\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(nn_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import train, test\n",
    "from torch import nn\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "125",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 125",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/sdk/Work/estsoft/Task/2023-11-13-sklearn/main.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sdk/Work/estsoft/Task/2023-11-13-sklearn/main.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(training_dataloader, nn_model, loss, optimizer)\n",
      "File \u001b[0;32m~/Work/estsoft/Task/2023-11-13-sklearn/utils.py:9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m      8\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     10\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     \u001b[39m# Compute prediction error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 125"
     ]
    }
   ],
   "source": [
    "train(training_dataloader, nn_model, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_train = one_hot_encoder.fit_transform(X).toarray()\n",
    "X_test = one_hot_encoder.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 34)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 1., 1., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 1., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, y.array, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor, LongTensor, nn, optim\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from model import nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdk/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "batch_no = len(x_train) // batch_size\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch {}'.format(epoch+1))\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    # Mini batch learning\n",
    "    for i in range(batch_no):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        x_var = Variable(FloatTensor(x_train[start:end]))\n",
    "        y_var = Variable(LongTensor(y_train[start:end]))\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        ypred_var = nn_model(x_var)\n",
    "        loss =criterion(ypred_var, y_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.79\n"
     ]
    }
   ],
   "source": [
    "test_var = Variable(FloatTensor(x_val), requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    result = nn_model(test_var)\n",
    "values, labels = torch.max(result, 1)\n",
    "num_right = np.sum(labels.data.numpy() == y_val)\n",
    "print('Accuracy {:.2f}'.format(num_right / len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_var = Variable(FloatTensor(X_test), requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    result = nn_model(X_test_var)\n",
    "values, labels = torch.max(result, 1)\n",
    "survived = labels.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_passenger_id = df_test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Complete!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "submission = [['PassengerId', 'Survived']]\n",
    "for i in range(len(survived)):\n",
    "    submission.append([X_test_passenger_id[i], survived[i]])\n",
    "\n",
    "with open('submission.csv', 'w') as submissionFile:\n",
    "    writer = csv.writer(submissionFile)\n",
    "    writer.writerows(submission)\n",
    "    \n",
    "print('Writing Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "77033"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MathAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
